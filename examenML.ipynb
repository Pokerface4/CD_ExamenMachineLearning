{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8516852,"sourceType":"datasetVersion","datasetId":5084906}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-29T04:36:30.483445Z","iopub.execute_input":"2024-05-29T04:36:30.483820Z","iopub.status.idle":"2024-05-29T04:36:30.892321Z","shell.execute_reply.started":"2024-05-29T04:36:30.483791Z","shell.execute_reply":"2024-05-29T04:36:30.890995Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/estudiantes/estudiantes.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Cargar los datos","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/estudiantes/estudiantes.csv')\n\ndf.head()\n#print(df.shape)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T04:36:43.345649Z","iopub.execute_input":"2024-05-29T04:36:43.346090Z","iopub.status.idle":"2024-05-29T04:36:43.385474Z","shell.execute_reply.started":"2024-05-29T04:36:43.346051Z","shell.execute_reply":"2024-05-29T04:36:43.384373Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"  escuela sexo  edad direccion tamano_familia estatus_padres  educacion_madre  \\\n0      GP    F    18         U            GT3              A                4   \n1      GP    F    17         U            GT3              T                1   \n2      GP    F    15         U            LE3              T                1   \n3      GP    F    15         U            GT3              T                4   \n4      GP    F    16         U            GT3              T                3   \n\n   educacion_padre trabajo_madre trabajo_padre  ...  \\\n0                4       at_home       teacher  ...   \n1                1       at_home         other  ...   \n2                1       at_home         other  ...   \n3                2        health      services  ...   \n4                3         other         other  ...   \n\n  calidad_relaciones_familiares tiempo_libre  salidas  \\\n0                             4            3        4   \n1                             5            3        3   \n2                             4            3        2   \n3                             3            2        2   \n4                             4            3        2   \n\n   consume_alc_entre_semana  consume_alc_fin_semana salud ausencias  P1  P2  \\\n0                         1                       1     3         6   5   6   \n1                         1                       1     3         4   5   5   \n2                         2                       3     3        10   7   8   \n3                         1                       1     5         2  15  14   \n4                         1                       2     5         4   6  10   \n\n   P3  \n0   6  \n1   6  \n2  10  \n3  15  \n4  10  \n\n[5 rows x 33 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>escuela</th>\n      <th>sexo</th>\n      <th>edad</th>\n      <th>direccion</th>\n      <th>tamano_familia</th>\n      <th>estatus_padres</th>\n      <th>educacion_madre</th>\n      <th>educacion_padre</th>\n      <th>trabajo_madre</th>\n      <th>trabajo_padre</th>\n      <th>...</th>\n      <th>calidad_relaciones_familiares</th>\n      <th>tiempo_libre</th>\n      <th>salidas</th>\n      <th>consume_alc_entre_semana</th>\n      <th>consume_alc_fin_semana</th>\n      <th>salud</th>\n      <th>ausencias</th>\n      <th>P1</th>\n      <th>P2</th>\n      <th>P3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>GP</td>\n      <td>F</td>\n      <td>18</td>\n      <td>U</td>\n      <td>GT3</td>\n      <td>A</td>\n      <td>4</td>\n      <td>4</td>\n      <td>at_home</td>\n      <td>teacher</td>\n      <td>...</td>\n      <td>4</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>6</td>\n      <td>5</td>\n      <td>6</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GP</td>\n      <td>F</td>\n      <td>17</td>\n      <td>U</td>\n      <td>GT3</td>\n      <td>T</td>\n      <td>1</td>\n      <td>1</td>\n      <td>at_home</td>\n      <td>other</td>\n      <td>...</td>\n      <td>5</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>5</td>\n      <td>5</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>GP</td>\n      <td>F</td>\n      <td>15</td>\n      <td>U</td>\n      <td>LE3</td>\n      <td>T</td>\n      <td>1</td>\n      <td>1</td>\n      <td>at_home</td>\n      <td>other</td>\n      <td>...</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>10</td>\n      <td>7</td>\n      <td>8</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>GP</td>\n      <td>F</td>\n      <td>15</td>\n      <td>U</td>\n      <td>GT3</td>\n      <td>T</td>\n      <td>4</td>\n      <td>2</td>\n      <td>health</td>\n      <td>services</td>\n      <td>...</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>2</td>\n      <td>15</td>\n      <td>14</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>GP</td>\n      <td>F</td>\n      <td>16</td>\n      <td>U</td>\n      <td>GT3</td>\n      <td>T</td>\n      <td>3</td>\n      <td>3</td>\n      <td>other</td>\n      <td>other</td>\n      <td>...</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>5</td>\n      <td>4</td>\n      <td>6</td>\n      <td>10</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 33 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Preparar los datos","metadata":{}},{"cell_type":"code","source":"#Eliminar filas con valores nulos, esto es opcional ya que mejor lo remplazamos por ceros\n#df= df.dropna()\n\n#verificar que los tipos de datos de cada columna sean correcto\n#tipos_de_dato = df.dtypes\n#print(tipos_de_dato)\n\n#Hacer que la codificacion este correcta para que no haya errores de caracteres.\n# Convertir todas las celdas del DataFrame a UTF-8\n#data_frame = data_frame.applymap(lambda x: x.encode('latin-1').decode('utf-8', 'ignore'))\n\n# Encontrar registros con todos los valores duplicados\n#duplicados_completos = df[df.duplicated(df.columns, keep=False)]\n\n#Imprimir los registros completos duplicados si los hay\n#if not duplicados_completos.empty:\n  #  print(\"SI HAY:\")\n#else:\n  #  print(\"No hay registros con todos los valores iguales en el DataFrame.\")\n    \n# Eliminar registros duplicados del DataFrame\n#data_frame_sin_duplicados = data_frame.drop_duplicates()\n# Imprimir información sobre la cantidad de registros eliminados\n#registros_duplicados_elim = len(data_frame) - len(data_frame_sin_duplicados)\n#print(\"Se eliminaron {} registros duplicados del DataFrame.\".format(registros_duplicados_elim))\n#data_frame = data_frame_sin_duplicados\n\n#Remplazar valores nulos de registros por 0\n#data_frame.fillna(0, inplace=True)\n#Verificar si hay alguna celda nula en el DataFrame\n#hay_nulos = df.isnull().any()\n#if hay_nulos.any():\n #   print(\"Hay al menos una celda nula en el DataFrame.\")\n#else:\n #   print(\"No hay celdas nulas en el DataFrame.\")","metadata":{"execution":{"iopub.status.busy":"2024-05-25T20:30:27.332122Z","iopub.execute_input":"2024-05-25T20:30:27.332506Z","iopub.status.idle":"2024-05-25T20:30:27.344486Z","shell.execute_reply.started":"2024-05-25T20:30:27.332479Z","shell.execute_reply":"2024-05-25T20:30:27.343047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Agregar columna estatus\nesta columna marca un reprobado si en algun parcial el alumno saco menos del minimo aprobatorio (14)","metadata":{}},{"cell_type":"code","source":"#hola mundo\n# Añadir la columna 'estatus'\ndf['estatus'] = df.apply(lambda row: '1' if row['P1'] < 14 or row['P2'] < 14 or row['P3'] < 14 else '0', axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T05:18:59.328267Z","iopub.execute_input":"2024-05-29T05:18:59.329357Z","iopub.status.idle":"2024-05-29T05:18:59.346453Z","shell.execute_reply.started":"2024-05-29T05:18:59.329315Z","shell.execute_reply":"2024-05-29T05:18:59.345336Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Cantidad de estudiantes aprobados: 73\nCantidad de estudiantes reprobados: 322\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Modelo","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.layers import Input, Dense # type: ignore\nfrom tensorflow.keras.models import Model # type: ignore\n\nepocas = 50\nentrenamiento = 0.70\nsize = [13, 6]\n\nentradas = ['direccion', 'tamano_familia', 'estatus_padres', 'educacion_madre', 'educacion_padre','trabajo_madre','trabajo_padre','razon_escuela','traslado_escuela','tiempo_estudio','reprobacion','apoyo_educativo_adicional','apoyo_educativo_familiar','clases_extra_pagas','actividades_extracurriculares','asistio_guarderia','quiere_educacion_superior','internet','en_relacion_romantica','calidad_relaciones_familiares','tiempo_libre','salidas','consume_alc_entre_semana','consume_alc_fin_semana','salud','ausencias']\n\n# Codificar las columnas categóricas a valores numéricos\nlabel_encoders = {}\nfor column in entradas:\n    if df[column].dtype == 'object':\n        le = LabelEncoder()\n        df[column] = le.fit_transform(df[column])\n        label_encoders[column] = le\n\n# Preparar los datos de entrada y salida\ndatos_entrada = df[entradas].values\ndatos_salida = df[['P1', 'P2', 'P3', 'estatus']].values\n\n\n# Dividir los datos en Training set y Validation set\ncantidad_datos = len(df)\nentrenamiento = int(cantidad_datos * entrenamiento)\n\ntraining_input = datos_entrada[:entrenamiento]\ntraining_output = datos_salida[:entrenamiento]\nvalidation_input = datos_entrada[entrenamiento:]\nvalidation_output = datos_salida[entrenamiento:]\n\n\n# Convertir los valores a tensores\ntrain_inputs = tf.convert_to_tensor(training_input, dtype=tf.float32)\ntrain_outputs_continuos = tf.convert_to_tensor(training_output[:, :3], dtype=tf.float32)\ntrain_outputs_binario = tf.convert_to_tensor(training_output[:, 3], dtype=tf.float32)\nval_inputs = tf.convert_to_tensor(validation_input, dtype=tf.float32)\nval_outputs_continuos = tf.convert_to_tensor(validation_output[:, :3], dtype=tf.float32)\nval_outputs_binario = tf.convert_to_tensor(validation_output[:, 3], dtype=tf.float32)\n\n# Definir el modelo\ninput_layer = Input(shape=(len(entradas),))\nhidden_layer = Dense(4, activation='relu')(input_layer)\noutput_continuos = Dense(3, activation='linear')(hidden_layer)  # Tres salidas lineales\noutput_binario = Dense(1, activation='sigmoid')(hidden_layer)  # Una salida sigmoide\n\nmodel = Model(inputs=input_layer, outputs=[output_continuos, output_binario])\n\n# Compilar el modelo\nmodel.compile(optimizer='adam', loss=['mean_squared_error', 'binary_crossentropy'])\n\n# Entrenar el modelo con datos de entrenamiento y validación\nhistory = model.fit(train_inputs, [train_outputs_continuos, train_outputs_binario], epochs=epocas, validation_split=0.2, batch_size=32, verbose=1)\n\n# Evaluar el modelo con los datos de validación\nloss = model.evaluate(val_inputs, [val_outputs_continuos, val_outputs_binario])\nprint(f'Loss en el conjunto de validación: {loss}')\n\n# Predecir con nuevas entradas\npredicciones_continuos, predicciones_binario = model.predict(val_inputs)\n\n# Aplicar umbral a las predicciones binarias\npredicciones_binario = (predicciones_binario > 0.5).astype(int)\n\n# Crear una figura y dos subplots\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(size[0], size[1]))\n\n# Obtener la pérdida del historial de entrenamiento\nloss = history.history['loss']\n\n# Graficar la pérdida en el primer subplot\nepochs = range(1, len(loss) + 1)\nax1.plot(epochs, loss, 'b', label='Pérdida de entrenamiento')\nax1.set_title('Pérdida durante entrenamiento del modelo')\nax1.set_xlabel('Épocas')\nax1.set_ylabel('Pérdida')\nax1.legend()\n\n# Graficar las salidas esperadas y las predicciones en el segundo subplot\nfor i in range(3):  # Iterar sobre las tres salidas continuas (P1, P2, P3)\n    ax2.plot(range(len(validation_output)), validation_output[:, i], 'bo-', label=f'Salida esperada {i+1}' if i == 0 else \"\")\n    ax2.plot(range(len(predicciones_continuos)), predicciones_continuos[:, i], 'ro-', label=f'Predicciones {i+1}' if i == 0 else \"\")\n\nax2.plot(range(len(validation_output)), validation_output[:, 3], 'go-', label='Estatus esperado')\nax2.plot(range(len(predicciones_binario)), predicciones_binario, 'mo-', label='Predicción estatus')\n\nax2.set_title('Salidas esperadas y predicciones')\nax2.set_xlabel('Muestras')\nax2.set_ylabel('Valor')\nax2.legend()\n\n# Ajustar los subplots para evitar solapamiento\nplt.tight_layout()\n\n# Mostrar la figura con los dos subplots\nplt.show()\n\n# Función para predecir con nuevos datos\ndef predecir_nuevo(direccion, tamano_familia, estatus_padres, educacion_madre, educacion_padre, trabajo_madre, trabajo_padre,\n                   razon_escuela, traslado_escuela, tiempo_estudio, reprobacion, apoyo_educativo_adicional, apoyo_educativo_familiar,\n                   clases_extra_pagas, actividades_extracurriculares, asistio_guarderia, quiere_educacion_superior, internet,\n                   en_relacion_romantica, calidad_relaciones_familiares, tiempo_libre, salidas, consume_alc_entre_semana,\n                   consume_alc_fin_semana, salud, ausencias):\n\n    nuevo_dato = np.array([[direccion, tamano_familia, estatus_padres, educacion_madre, educacion_padre, trabajo_madre,\n                            trabajo_padre, razon_escuela, traslado_escuela, tiempo_estudio, reprobacion, apoyo_educativo_adicional,\n                            apoyo_educativo_familiar, clases_extra_pagas, actividades_extracurriculares, asistio_guarderia,\n                            quiere_educacion_superior, internet, en_relacion_romantica, calidad_relaciones_familiares, tiempo_libre,\n                            salidas, consume_alc_entre_semana, consume_alc_fin_semana, salud, ausencias]])\n\n    # Normalizar el nuevo dato\n    for i, column in enumerate(entradas):\n        if column in label_encoders:\n            nuevo_dato[:, i] = label_encoders[column].transform(nuevo_dato[:, i])\n        max_valor = df[column].max()\n        min_valor = df[column].min()\n        nuevo_dato[:, i] = nuevo_dato[:, i] / abs(max_valor - min_valor)\n    \n    # Predecir con el nuevo dato\n    prediccion_continuos, prediccion_binario = model.predict(nuevo_dato)\n    prediccion_binario = (prediccion_binario > 0.5).astype(int)\n    return prediccion_continuos, prediccion_binario\n\n# Ejemplo de predicción con un nuevo dato (puedes cambiar los valores según tu interés)\nnueva_prediccion_continuos, nueva_prediccion_binario = predecir_nuevo(1, 2, 1, 3, 4, 2, 3, 1, 2, 2, 0, 0, 1, 0, 1, 0, 1, 1, 0, 4, 2, 3, 2, 3, 4, 6)\nprint('parciales:', nueva_prediccion_continuos)\nprint('estatus:', nueva_prediccion_binario)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T05:38:07.618215Z","iopub.execute_input":"2024-05-29T05:38:07.618602Z","iopub.status.idle":"2024-05-29T05:38:14.883233Z","shell.execute_reply.started":"2024-05-29T05:38:07.618565Z","shell.execute_reply":"2024-05-29T05:38:14.881687Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 132.1919 - val_loss: 120.3770\nEpoch 2/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 128.7842 - val_loss: 118.4918\nEpoch 3/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 120.4873 - val_loss: 116.5915\nEpoch 4/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 125.6526 - val_loss: 114.5462\nEpoch 5/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 123.1730 - val_loss: 112.3572\nEpoch 6/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 117.7610 - val_loss: 110.0169\nEpoch 7/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 114.1079 - val_loss: 107.5216\nEpoch 8/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 116.5543 - val_loss: 104.8131\nEpoch 9/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 108.6542 - val_loss: 101.8414\nEpoch 10/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 104.1369 - val_loss: 98.3917\nEpoch 11/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 106.6346 - val_loss: 94.3953\nEpoch 12/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 99.3719 - val_loss: 89.8714\nEpoch 13/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 99.1840 - val_loss: 84.8515\nEpoch 14/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 84.8118 - val_loss: 79.6706\nEpoch 15/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 85.1710 - val_loss: 74.4532\nEpoch 16/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 78.9639 - val_loss: 69.4774\nEpoch 17/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 74.7941 - val_loss: 64.7818\nEpoch 18/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 68.7176 - val_loss: 60.3857\nEpoch 19/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 70.5545 - val_loss: 56.1869\nEpoch 20/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 65.9336 - val_loss: 52.2255\nEpoch 21/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 62.2531 - val_loss: 48.5543\nEpoch 22/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 54.2062 - val_loss: 45.1586\nEpoch 23/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 48.9002 - val_loss: 42.0548\nEpoch 24/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 46.7027 - val_loss: 39.1829\nEpoch 25/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 45.0369 - val_loss: 36.5662\nEpoch 26/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 39.8638 - val_loss: 34.2198\nEpoch 27/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 39.7756 - val_loss: 32.0731\nEpoch 28/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 36.8296 - val_loss: 30.1546\nEpoch 29/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 34.6644 - val_loss: 28.4589\nEpoch 30/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 33.3633 - val_loss: 26.9497\nEpoch 31/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32.3861 - val_loss: 25.6548\nEpoch 32/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.8439 - val_loss: 24.4976\nEpoch 33/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 27.3806 - val_loss: 23.4990\nEpoch 34/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 25.8001 - val_loss: 22.6582\nEpoch 35/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 26.7114 - val_loss: 21.9167\nEpoch 36/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 23.7055 - val_loss: 21.2851\nEpoch 37/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 24.9844 - val_loss: 20.7631\nEpoch 38/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 23.2158 - val_loss: 20.2960\nEpoch 39/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 25.1907 - val_loss: 19.8986\nEpoch 40/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 21.8079 - val_loss: 19.5674\nEpoch 41/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 22.4465 - val_loss: 19.3011\nEpoch 42/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 24.0637 - val_loss: 19.0660\nEpoch 43/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 21.5216 - val_loss: 18.8796\nEpoch 44/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 21.4202 - val_loss: 18.7120\nEpoch 45/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 21.6503 - val_loss: 18.5706\nEpoch 46/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 21.5508 - val_loss: 18.4468\nEpoch 47/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 20.8788 - val_loss: 18.3334\nEpoch 48/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 20.2507 - val_loss: 18.2419\nEpoch 49/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 20.1600 - val_loss: 18.1596\nEpoch 50/50\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 20.9779 - val_loss: 18.0902\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.2490 \nLoss en el conjunto de validación: 18.487470626831055\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\nparciales: [[0.11493674 1.9906554  4.4038367 ]]\nestatus: [[1]]\n","output_type":"stream"}]}]}